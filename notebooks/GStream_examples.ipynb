{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "\u001b[1;31mE: \u001b[0mUnable to locate package gstreamer1.0-plugins-{base,good,bad,ugly}\u001b[0m\n",
      "Requirement already satisfied: opencv-python in /home/nvidia/.local/lib/python3.8/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: opencv-contrib-python in /home/nvidia/.local/lib/python3.8/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /home/nvidia/.local/lib/python3.8/site-packages (from opencv-python) (1.23.5)\n",
      "Requirement already satisfied: pycairo in /home/nvidia/.local/lib/python3.8/site-packages (1.23.0)\n",
      "Requirement already satisfied: PyGObject in /home/nvidia/.local/lib/python3.8/site-packages (3.42.2)\n",
      "Requirement already satisfied: pycairo>=1.16.0 in /home/nvidia/.local/lib/python3.8/site-packages (from PyGObject) (1.23.0)\n"
     ]
    }
   ],
   "source": [
    "!pkexec apt install libgstreamer1.0-0 gstreamer1.0-plugins-{base,good,bad,ugly} gstreamer1.0-tools python3-gi gir1.2-gstreamer-1.0 python3-gi-cairo gir1.2-gtk-3.0 libgirepository1.0-dev gcc libcairo2-dev pkg-config python3-dev -y\n",
    "!pip3 install opencv-python opencv-contrib-python\n",
    "!pip3 install pycairo\n",
    "!pip3 install PyGObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import gi\n",
    "import numpy as np\n",
    "\n",
    "# Specifying required version is necessary before importing the following packages\n",
    "gi.require_version(\"Gst\", \"1.0\")\n",
    "gi.require_version(\"GstApp\", \"1.0\")\n",
    "\n",
    "# Although unused, GstApp is needed for using appsink instead of the default sink\n",
    "from gi.repository import Gst, GLib, GstApp\n",
    "_ = GstApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GStreamer\n",
    "Gst.init()\n",
    "\n",
    "main_loop = GLib.MainLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '../data/250m_day_2walking.mp4' #Make sure that you have some video file in this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!video_path=../data/250m_day_2walking.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Terminal) Read a video file from the computer and display it immediately\n",
    "\n",
    "1) <b>filesrc location</b> - specify source video location on computer\n",
    "\n",
    "2) <b>decodebin</b> - constructs decoding pipeline for the incoming data that fits the properties of the data\n",
    "\n",
    "3) <b>videoconvert</b> - converts the video into a format that is supported by the downstream video sink\n",
    "\n",
    "4) <b>autovideosink</b> - output video to the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pipeline to PAUSED ...\n",
      "Pipeline is PREROLLING ...\n",
      "Redistribute latency...\n",
      "Redistribute latency...\n",
      "Pipeline is PREROLLED ...\n",
      "Setting pipeline to PLAYING ...\n",
      "New clock: GstSystemClock\n",
      "ERROR: from element /GstPipeline:pipeline0/GstAutoVideoSink:autovideosink0/GstXvImageSink:autovideosink0-actual-sink-xvimage: Output window was closed\n",
      "Additional debug info:\n",
      "xvimagesink.c(554): gst_xv_image_sink_handle_xevents (): /GstPipeline:pipeline0/GstAutoVideoSink:autovideosink0/GstXvImageSink:autovideosink0-actual-sink-xvimage\n",
      "Execution ended after 0:00:01.972831611\n",
      "Setting pipeline to NULL ...\n",
      "Freeing pipeline ...\n"
     ]
    }
   ],
   "source": [
    "!gst-launch-1.0 filesrc location=$video_path ! decodebin ! videoconvert ! autovideosink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Jetson Terminal) Read a video file from the computer and display it immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pipeline to PAUSED ...\n",
      "Pipeline is PREROLLING ...\n",
      "Redistribute latency...\n",
      "Redistribute latency...\n",
      "Pipeline is PREROLLED ...\n",
      "Setting pipeline to PLAYING ...\n",
      "New clock: GstSystemClock\n",
      "ERROR: from element /GstPipeline:pipeline0/GstAutoVideoSink:autovideosink0/GstXvImageSink:autovideosink0-actual-sink-xvimage: Output window was closed\n",
      "Additional debug info:\n",
      "xvimagesink.c(554): gst_xv_image_sink_handle_xevents (): /GstPipeline:pipeline0/GstAutoVideoSink:autovideosink0/GstXvImageSink:autovideosink0-actual-sink-xvimage\n",
      "Execution ended after 0:00:01.830288215\n",
      "Setting pipeline to NULL ...\n",
      "Freeing pipeline ...\n"
     ]
    }
   ],
   "source": [
    "!gst-launch-1.0 filesrc location=$video_path ! decodebin3 ! videoconvert ! autovideosink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Python) Read a video file from the computer and display it immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enum GST_STATE_CHANGE_ASYNC of type Gst.StateChangeReturn>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create reading pipeline\n",
    "gst = f'filesrc location={video_path} ! decodebin ! videoconvert ! autovideosink'\n",
    "pipeline = Gst.parse_launch(gst)\n",
    "\n",
    "# By default the pipeline's state is set to NULL, we need to manually tell it to start reading the video\n",
    "pipeline.set_state(Gst.State.PLAYING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Python) Read video file from computer into frames as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Gst.Sample frame format to a usable numpy array\n",
    "\n",
    "def gst_to_numpy(sample_frame: Gst.Sample, num_channels: int = 3, dtype=np.uint8) -> np.ndarray:\n",
    "    buffer = sample_frame.get_buffer()  # Frame data\n",
    "    caps = sample_frame.get_caps()  # Metadata\n",
    "    height, width = caps.get_structure(0).get_value('height'), caps.get_structure(0).get_value('width')\n",
    "    \n",
    "    frame_np = np.ndarray(shape=(height, width, num_channels),\n",
    "                          buffer=buffer.extract_dup(0, buffer.get_size() * 2),\n",
    "                          dtype=dtype)\n",
    "\n",
    "    return frame_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_gst(gst_command: str, app_name: str):\n",
    "    # Setup pipeline\n",
    "    pipeline = Gst.parse_launch(gst_command)\n",
    "\n",
    "    # Get pipeline sink, this is where we pull the video frames from\n",
    "    appsink = pipeline.get_by_name(app_name)\n",
    "\n",
    "    pipeline.set_state(Gst.State.PLAYING)\n",
    "    \n",
    "    # Read frames from the appsink and display them using OpenCV\n",
    "    timeout = Gst.SECOND\n",
    "    while True:\n",
    "        sample_frame = appsink.try_pull_sample(timeout)  # get sample from sink\n",
    "        if not sample_frame:\n",
    "            continue\n",
    "        frame = gst_to_numpy(sample_frame=sample_frame)\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    pipeline.set_state(Gst.State.NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the gst command\n",
    "app_name = 'my_video_sink'\n",
    "\n",
    "gst = f\"filesrc location={video_path} ! decodebin ! videoconvert ! video/x-raw, format=BGR \"\\\n",
    "      f\"! appsink name={app_name}\"\n",
    "\n",
    "start_gst(gst_command=gst, app_name=app_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Terminal) Stream a video over RTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) <b>x264enc</b> - Encodes the raw video to H264 compressed data\n",
    "\n",
    "2) <b>rtph264pay</b> - Payload encoder - encodes the H264 video into RTP packets, ready to be transmitted\n",
    "\n",
    "3) <b>udpsink</b> - Streams the RTP payload packets over the UDP protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pipeline to PAUSED ...\n",
      "Pipeline is PREROLLING ...\n",
      "Redistribute latency...\n",
      "Redistribute latency...\n",
      "Redistribute latency...\n",
      "Pipeline is PREROLLED ...\n",
      "Setting pipeline to PLAYING ...\n",
      "New clock: GstSystemClock\n"
     ]
    }
   ],
   "source": [
    "!gst-launch-1.0 filesrc location=$video_path ! decodebin ! x264enc ! rtph264pay ! udpsink host=127.0.0.1 port=5004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Terminal) Read a stream over RTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) <b>udpsrc</b> - Reads stream from a specified port\n",
    "\n",
    "2) <b>application/x-rtp</b> - Sets up an RTP stream and its parameters\n",
    "\n",
    "3) <b>queue</b> - Puts the received stream into a queue and moderates how much buffers are pushed into the queue,  will block new buffers if the limit is exceeded\n",
    "\n",
    "4) <b>rtph264depay</b> - Extracts H264 formatted video from the RTP packets\n",
    "\n",
    "5) <b>h264parse</b> - Parses the H264 video\n",
    "\n",
    "6) <b>avdec_h264</b> - Decodes the parsed H264 video\n",
    "\n",
    "7) <b>decodebin</b> - Further decodes the video from the H264 format\n",
    "\n",
    "8) <b>videoconvert</b> - Converts the video into a format that is understood by the video sink\n",
    "\n",
    "9) <b>videoscale</b> - Resizes to the desired size. By default tries to resize to the source size, so no scaling is needed \n",
    "\n",
    "10) <b>sync</b> - False sends over the frames as they arrive, True waits for the timestamp to match the frame's timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pipeline to PAUSED ...\n",
      "Pipeline is live and does not need PREROLL ...\n",
      "Setting pipeline to PLAYING ...\n",
      "New clock: GstSystemClock\n",
      "Redistribute latency...\n",
      "Redistribute latency...\n",
      "ERROR: from element /GstPipeline:pipeline0/GstAutoVideoSink:autovideosink0/GstXvImageSink:autovideosink0-actual-sink-xvimage: Output window was closed\n",
      "Additional debug info:\n",
      "xvimagesink.c(554): gst_xv_image_sink_handle_xevents (): /GstPipeline:pipeline0/GstAutoVideoSink:autovideosink0/GstXvImageSink:autovideosink0-actual-sink-xvimage\n",
      "Execution ended after 0:00:43.201976372\n",
      "Setting pipeline to NULL ...\n",
      "Freeing pipeline ...\n"
     ]
    }
   ],
   "source": [
    "!gst-launch-1.0 udpsrc port=5004 ! application/x-rtp, media=video, clock-rate=90000, encoding-name=H264, payload=96 ! queue ! rtph264depay ! h264parse ! avdec_h264 ! decodebin ! videoconvert ! videoscale ! autovideosink sync=false\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Python) Read a stream over RTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "port = 5004\n",
    "app_name = 'my_video_sink'\n",
    "gst = f'udpsrc port={port} ! application/x-rtp, media=video, clock-rate=90000, encoding-name=H264, payload=96 ! '\\\n",
    "      f'queue ! rtph264depay ! h264parse ! avdec_h264 ! decodebin ! videoconvert ! video/x-raw, format=BGR ! ' \\\n",
    "      f'videoscale ! appsink name={app_name} sync=false'\n",
    "\n",
    "start_gst(gst_command=gst, app_name=app_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
